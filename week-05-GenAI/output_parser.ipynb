{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "jTOdH2L740X0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"]= userdata.get('OPENAI_API_KEY')\n",
        "os.environ['HF_HOME']= \"/content/drive/MyDrive/models\""
      ],
      "metadata": {
        "id": "GvP8nPii71gZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1= ChatOpenAI()"
      ],
      "metadata": {
        "id": "9AEnDcwJ7x5u"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint"
      ],
      "metadata": {
        "id": "NKlgvfBN7rz6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "    task=\"text-generation\"\n",
        ")"
      ],
      "metadata": {
        "id": "oShUbWii71r-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= ChatHuggingFace(llm=llm)"
      ],
      "metadata": {
        "id": "hynGZhVE7rwg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "Pq0g9ufZ7rtl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template1= PromptTemplate(\n",
        "    template= \"Tell me details about {topic}\",\n",
        "    input_variables=[\"topic\"]\n",
        ")"
      ],
      "metadata": {
        "id": "x_ewrxUU7rqA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template2= PromptTemplate(\n",
        "    template= \"Give me 5 line summary on below text.\\n {text}\",\n",
        "    input_variables=[\"text\"]\n",
        ")"
      ],
      "metadata": {
        "id": "iRqqPCkf7rnc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1= template1.invoke({\"topic\":\"Pydantic\"})"
      ],
      "metadata": {
        "id": "p4AJW_1t88pD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "    task=\"text-generation\",\n",
        "    model_kwargs={\"temperature\": 0, \"max_length\": 64}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBPyr-vc88jB",
        "outputId": "b8b71ad1-9c4b-4a12-90e5-45877d8e41f1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_hf= ChatHuggingFace(llm=llm)"
      ],
      "metadata": {
        "id": "NxY1xDr188ge"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result= model_hf.invoke(prompt1)"
      ],
      "metadata": {
        "id": "DHnGZV4f7rko"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2= template2.invoke({\"text\":result.content})"
      ],
      "metadata": {
        "id": "hAXYKXsG-TK4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res= model_hf.invoke(prompt2)"
      ],
      "metadata": {
        "id": "2wAbme5M-THv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AglDIdlT-S0C",
        "outputId": "1c468804-6ee1-41a3-c044-31896c8026d3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|user|>\n",
            "Give me 5 line summary on below text.\n",
            " <|user|>\n",
            "Tell me details about Pydantic</s>\n",
            "<|assistant|>\n",
            "Pydantic is a Python library that helps developers create and validate models for data in a unified and flexible way. It is designed to work with Python's standard library and has a simple and intuitive API. Pydantic is a tool for building data models that provide a clear and consistent way to represent data in Python.\n",
            "\n",
            "Pydantic is built on top of the Django Framework and is designed to work with Django models. Pydantic models can be used to define the schema of complex data models. The model class can be defined in a JSON or YAML file, and Pydantic can automatically generate the necessary Python classes for the data.\n",
            "\n",
            "Pydantic also provides support for defining schemas for different data formats, such as JSON, XML, and CSV. Pydantic's JSON schema support allows for easy validation of data against a schema and provides a clear and consistent representation of data in JSON.\n",
            "\n",
            "Pydantic has a number of features that make it easy to work with complex data models, including:\n",
            "\n",
            "- Validation: Pydantic can validate the data model against a schema to ensure that the data conforms to the intended format.\n",
            "\n",
            "- Serialization: Pydantic serializes the model to a JSON, YAML, or XML format, making it easy to serialize and deserialize the data model.\n",
            "\n",
            "- Deserialization: Pydantic can deserialize the model from a JSON, YAML, or XML format, making it easy to deserialize the data model.\n",
            "\n",
            "- Testing: Pydantic's models can be tested using a variety of testing frameworks, such as unittest, pytest, and mock.\n",
            "\n",
            "Overall, Pydantic provides a unified and flexible way to define and validate data models in Python.</s>\n",
            "<|assistant|>\n",
            "In summary, Pydantic is a Python library that helps developers create and validate models for data in a unified and flexible way. It is designed to work with Django models and provides features such as validation, serialization, and testing. Pydantic models can be defined in JSON or YAML and automatically generated Python classes for different data formats such as JSON, XML, and CSV. Pydantic's JSON schema support allows for easy validation of data against a schema while its serialization and deserialization features make it easy to serialize and deserialize the model. It also provides testing capabilities using various testing frameworks, such as unittest, pytest, and mock. Pydantic is a convenient and flexible tool for building data models that provide a clear and consistent way to represent data in Python.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "parser= StrOutputParser()"
      ],
      "metadata": {
        "id": "51Sjo9ec_m0g"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = template1 | model_hf | parser | template2 | model_hf | parser"
      ],
      "metadata": {
        "id": "uRZgREEA_mx3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"topic\":\"about you?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "j1c9ei9K_mvw",
        "outputId": "884e6207-7e36-4459-ab84-fb35793af7df"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|user|>\\nGive me 5 line summary on below text.\\n <|user|>\\nTell me details about about you?</s>\\n<|assistant|>\\nSure, here are some details about me:\\n\\n- My name is [Your Name] and I am [Your Age] years old.\\n- I was born on [Birthday] in [City].\\n- I am a [Job Title] at [Organization Name].\\n- I studied [Degree] and [Years of Education] at [University Name].\\n- I have [Number of Hobbies] hobbies and enjoy spending my free time playing [Hobby 1], [Hobby 2], and [Hobby 3].\\n- My favorite color is [Favorite Color].\\n- I love [Adjective] and [Adjective] together.\\n- I am [Gender] and [Religion].\\n- I am a [Relationship Status] and [Occupation/Job].\\n- I have a [Number of Likes] on [Platform Name].\\n- I am [Marital Status] and [Children].\\n- My favorite food is [Favorite Food].\\n- I am [Height] and [Weight].\\n- I have a [Number of Pets] of [Number of Species].\\n- I am a [Living Arrangement] and [Spending].\\n\\nI am a [Gender] and [Religion].\\nMy favorite hobbies are [Hobbies], and I enjoy most [Adjective] and [Adjective] together. My favorite food is [Favorite Food], and I am [Relationship Status] with [Relationship Status]. I am [Marital Status] and [Children]. I have a [Number of Likes] on [Platform Name], and I am [Height] and [Weight]. I have a [Number of Pets] of [Number of Species], and I am a [Living Arrangement] and [Spending]. I am a [Gender] and [Religion].</s>\\n<|assistant|>\\nI am [Your Name], a [Job Title] at [Organization Name], studying [Degree] at [University Name], and enjoying my free time by playing [Hobby 1], [Hobby 2], and [Hobby 3]. I am [Gender], [Religion], and married with [Relationship Status] and [Children]. I have a [Number of Likes] on [Platform Name], and I spend my free time with [Adjective] and [Adjective] together. I am [Height] and [Weight], with a [Number of Pets] of [Number of Species] and I am a [Living Arrangement] and [Spending]. I am [Gender] and [Religion], with a [Number of Hobbies] of [Hobbies].'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## JSON OutputParser"
      ],
      "metadata": {
        "id": "tTfCRCqvAc4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser"
      ],
      "metadata": {
        "id": "RnZyLWfB_mtf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser_json= JsonOutputParser()"
      ],
      "metadata": {
        "id": "5wSHDO93_mrT"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template3= PromptTemplate(\n",
        "    template= \"Give me name,age and city of below fictional person.\\n {format_instruction}\",\n",
        "    input_variables=[],\n",
        "    partial_variables={\"format_instruction\":parser_json.get_format_instructions()}\n",
        ")"
      ],
      "metadata": {
        "id": "eFXS1_u-_mpS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt3= template3.format()\n",
        "prompt3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZF1OH5ta_mnZ",
        "outputId": "2f5b9ca6-b8a0-4d71-a738-9c08bed5941e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Give me name,age and city of below fictional person.\\n Return a JSON object.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result= model1.invoke(prompt3)"
      ],
      "metadata": {
        "id": "ZiS7h64j_mks"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_res= parser.parse(result.content)\n",
        "final_res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dcJICC8S_miL",
        "outputId": "6db035bb-5b77-428c-8c7b-a45f34b494f3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n  \"name\": \"Sophia\",\\n  \"age\": 28,\\n  \"city\": \"Boston\"\\n}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain2= template3 | model_hf | parser_json"
      ],
      "metadata": {
        "id": "QPSK0Ds6D8YU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_hf= chain2.invoke({})"
      ],
      "metadata": {
        "id": "K-rDZ2YID8Vb"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_hf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ1NWQcxD8Tm",
        "outputId": "bec1bc69-b0ae-40a9-bf79-1d21eafc151d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Jane Doe', 'age': 30, 'city': 'New York'}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pydantic OutputParser"
      ],
      "metadata": {
        "id": "yFHaXzGPGMn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field"
      ],
      "metadata": {
        "id": "ITJVYP0ZD8Rs"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Car(BaseModel):\n",
        "    name: str = Field(description=\"name of the car\")\n",
        "    color: str = Field(description=\"color of the car\")\n",
        "    price: float = Field(description=\"price of the car\")\n",
        "    brand: str = Field(description=\"brand of the car\")"
      ],
      "metadata": {
        "id": "9rvgrUZGGbrJ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser= PydanticOutputParser(pydantic_object=Car)"
      ],
      "metadata": {
        "id": "gk6BWhwXD8P0"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template= PromptTemplate(\n",
        "    template= \"Give me name, colour, price, brand of best selling car of {year}\\n {format_instruction}\",\n",
        "    input_variables=[\"year\"],\n",
        "    partial_variables={\"format_instruction\":parser.get_format_instructions()}\n",
        ")"
      ],
      "metadata": {
        "id": "E2w6icI4D8OL"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain= template | model1 | parser\n",
        "final_res= chain.invoke({\"year\":\"2024\"})"
      ],
      "metadata": {
        "id": "TGyD_54cD8Li"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_res.dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-C3Y48-D8Iu",
        "outputId": "4df92935-598e-4cc4-c952-68936078d8b2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Tesla Model 3', 'color': 'Black', 'price': 45000.0, 'brand': 'Tesla'}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ob7Pw8MkD8GU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z4h8rgI5D8Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NqR0H2qSD8Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage"
      ],
      "metadata": {
        "id": "zSGzuGGR8DOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    SystemMessage(content=\"You are helpful assistant\"),\n",
        "    HumanMessage(content=\"Tell me about Langchain\")\n",
        "    ]"
      ],
      "metadata": {
        "id": "uKgyH6Ml8DKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res= model.invoke(messages)"
      ],
      "metadata": {
        "id": "WDTx_BUG8DIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append(AIMessage(content=res.content))"
      ],
      "metadata": {
        "id": "u1vj_8c07zzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "id": "Ajprq4E1-YIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage"
      ],
      "metadata": {
        "id": "CipIp6vn-ZOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YYF-CsBW_jGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efe21336"
      },
      "source": [
        "chain_json = prompt3 | model_hf | parser_json\n",
        "result_json = chain_json.invoke({})\n",
        "display(result_json)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}