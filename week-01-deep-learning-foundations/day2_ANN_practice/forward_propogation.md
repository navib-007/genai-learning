# Forward Propagation is the process of passing input data through the layers of a neural network to get the final output.

## It happens layer by layer, using:
## Weights
## Biases
## Activation Functions (like sigmoid, ReLU)

## For input x, weights w, bias b:
## 𝑧=𝑤⋅𝑥+𝑏(linear step)
## 𝑎=𝜎(𝑧)(activation step, e.g., sigmoid)
