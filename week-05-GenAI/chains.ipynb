{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q5MVz45imLmL"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "khqjizEmmLip"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "model= ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "L9pr39rCmLgh"
      },
      "outputs": [],
      "source": [
        "parser= StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bzSWmPdJ7cZd"
      },
      "outputs": [],
      "source": [
        "prompt1= PromptTemplate(\n",
        "    input_variables=[\"name\"],\n",
        "    template=\"Tell me in details about the following \\n {name}\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pRT_X54SmLcv"
      },
      "outputs": [],
      "source": [
        "prompt2= PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=\"Tell me 5 most important points in engageable manner\\n {text}\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-qkslZoRmLah"
      },
      "outputs": [],
      "source": [
        "chain= prompt1 | model | parser | prompt2 | model | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "z-ozj9GhmLYm",
        "outputId": "f323903a-4da7-4563-d064-ba8243cf9deb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1. Transformers are a game-changing type of deep learning model in the field of artificial intelligence, known for their efficiency in handling sequential data.\\n\\n2. Based on self-attention mechanism, transformers can weigh the importance of different input tokens, allowing them to capture long-range dependencies in data effectively.\\n\\n3. Unlike traditional RNNs, transformers can process input sequences in parallel, making them much faster and more efficient, especially with long sequences of data.\\n\\n4. Transformers consist of an encoder and a decoder, each made up of multiple layers of self-attention and feedforward neural networks, which are adjusted during training to minimize a loss function.\\n\\n5. Popular transformer-based models like BERT, GPT, and T5 have shown impressive results in various NLP tasks, showcasing the power and versatility of transformer architecture in AI advancements.'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"name\":\"transformers in ai\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JUvdUPml3ndO"
      },
      "outputs": [],
      "source": [
        "# !pip install grandalf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lzJr_rSmLWq",
        "outputId": "ffdcb61b-b384-480b-df74-8e3d2f05b733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     +-------------+       \n",
            "     | PromptInput |       \n",
            "     +-------------+       \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "    +----------------+     \n",
            "    | PromptTemplate |     \n",
            "    +----------------+     \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "      +------------+       \n",
            "      | ChatOpenAI |       \n",
            "      +------------+       \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "   +-----------------+     \n",
            "   | StrOutputParser |     \n",
            "   +-----------------+     \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "+-----------------------+  \n",
            "| StrOutputParserOutput |  \n",
            "+-----------------------+  \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "    +----------------+     \n",
            "    | PromptTemplate |     \n",
            "    +----------------+     \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "      +------------+       \n",
            "      | ChatOpenAI |       \n",
            "      +------------+       \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "   +-----------------+     \n",
            "   | StrOutputParser |     \n",
            "   +-----------------+     \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "+-----------------------+  \n",
            "| StrOutputParserOutput |  \n",
            "+-----------------------+  \n"
          ]
        }
      ],
      "source": [
        "chain.get_graph().print_ascii()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsjYf6uI4CDq"
      },
      "source": [
        "## Parallel Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "y4BtBrcgmLUb"
      },
      "outputs": [],
      "source": [
        "model1= ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XVit4hCFmLSa"
      },
      "outputs": [],
      "source": [
        "model2= ChatOpenAI(model_name=\"gpt-4\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zC3ogySEmLQL"
      },
      "outputs": [],
      "source": [
        "prompt3= PromptTemplate(\n",
        "    input_variables=[\"para\"],\n",
        "    template=\"Generate a short summary, but cover all the important points from following \\n {para}\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "0Lv5eHUBmLOO"
      },
      "outputs": [],
      "source": [
        "prompt4= PromptTemplate(\n",
        "    input_variables=[\"para\"],\n",
        "    template=\"create a quiz having question and answers at least 4 from the following provided\\n {para}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "JViCWF1HmLMO"
      },
      "outputs": [],
      "source": [
        "prompt5= PromptTemplate(\n",
        "    input_variables=[\"summary\", \"quiz\"],\n",
        "    template=\"combine the summary {summary}\\n and quiz {quiz} in an engageable manner into single document\\n\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "TK946HY3mLJw"
      },
      "outputs": [],
      "source": [
        "sample_text=\"\"\"Combine SMOTE with Edited Nearest Neighbor (ENN) using Python to balance your dataset\n",
        "\n",
        "Motivation\n",
        "\n",
        "There are many methods to overcome imbalanced datasets in classification modeling by oversampling the minority class or undersampling the majority class. To increase the model performance even further, many researchers suggest combining oversampling and undersampling methods to balance the dataset better.\n",
        "\n",
        "In my previous article, I have already explained one of the combined oversampling and undersampling methods, named the SMOTE-Tomek Links method. This time, I will explain the other variation, by combining SMOTE and Edited Nearest Neighbor (ENN) method – or in short, SMOTE-ENN – and its implementation using Python.\n",
        "\n",
        "The Concept: K-Nearest Neighbor (KNN)\n",
        "\n",
        "The idea of KNN is to assume that the nearest neighbor of each data based on its distance is having a similar class. When the new observation in the dataset exists, KNN will search its K-nearest neighbor to determine the class that the new observation will belong to. Many distance metrics can be used to calculate each observation distance in KNN, but the most common one is by using Euclidean distance.\n",
        "\n",
        "For example, suppose that the dataset is consists of two classes, black and white. Now, suppose that there is a new observation with an unknown class. By using KNN, if the majority of the new observation’s K-nearest neighbor belongs to the black class, then the new observation will belong to that black class and vice versa.\n",
        "\n",
        "Given a dataset that consists of N observations, the algorithm of KNN can be explained as follows.\n",
        "\n",
        "Determine K, as the number of nearest neighbors.\n",
        "For each observation in the dataset, calculate the distance between each observation, then add the distance and the observation to an ordered set.\n",
        "Sort the ordered set of distances and observations in ascending order based on the distances.\n",
        "Pick the first K entries from the sorted ordered set. In other words, pick the K nearest neighbor of each observation.\n",
        "Return the majority class from the selected K entries.\n",
        "The Concept: Edited Nearest Neighbor (ENN)\n",
        "\n",
        "Developed by Wilson (1972), the ENN method works by finding the K-nearest neighbor of each observation first, then check whether the majority class from the observation’s k-nearest neighbor is the same as the observation’s class or not. If the majority class of the observation’s K-nearest neighbor and the observation’s class is different, then the observation and its K-nearest neighbor are deleted from the dataset. In default, the number of nearest-neighbor used in ENN is K=3.\n",
        "\n",
        "The algorithm of ENN can be explained as follows.\n",
        "\n",
        "Given the dataset with N observations, determine K, as the number of nearest neighbors. If not determined, then K=3.\n",
        "Find the K-nearest neighbor of the observation among the other observations in the dataset, then return the majority class from the K-nearest neighbor.\n",
        "If the class of the observation and the majority class from the observation’s K-nearest neighbor is different, then the observation and its K-nearest neighbor are deleted from the dataset.\n",
        "Repeat step 2 and 3 until the desired proportion of each class is fulfilled.\n",
        "This method is more powerful than Tomek Links, where ENN removes the observation and its K-nearest neighbor when the class of the observation and the majority class from the observation’s K-nearest neighbor are different, instead of just removing observation and its 1-nearest neighbor that are having different classes. Thus, ENN can be expected to give more in-depth data cleaning than Tomek Links.\n",
        "\n",
        "SMOTE-ENN Method\n",
        "\n",
        "Developed by Batista et al (2004), this method combines the SMOTE ability to generate synthetic examples for minority class and ENN ability to delete some observations from both classes that are identified as having different class between the observation’s class and its K-nearest neighbor majority class. The process of SMOTE-ENN can be explained as follows.\n",
        "\n",
        "(Start of SMOTE) Choose random data from the minority class.\n",
        "Calculate the distance between the random data and its k nearest neighbors.\n",
        "Multiply the difference with a random number between 0 and 1, then add the result to the minority class as a synthetic sample.\n",
        "Repeat step number 2–3 until the desired proportion of minority class is met. (End of SMOTE)\n",
        "(Start of ENN) Determine K, as the number of nearest neighbors. If not determined, then K=3.\n",
        "Find the K-nearest neighbor of the observation among the other observations in the dataset, then return the majority class from the K-nearest neighbor.\n",
        "If the class of the observation and the majority class from the observation’s K-nearest neighbor is different, then the observation and its K-nearest neighbor are deleted from the dataset.\n",
        "Repeat step 2 and 3 until the desired proportion of each class is fulfilled. (End of ENN)\n",
        "To understand more about this method in practice, here I will give some implementation of SMOTE-ENN in Python using imbalanced-learn library. For this article, the model that I will use is AdaBoost Classifier by using AdaBoostClassifier . And to evaluate our model, here I will use the Repeated Stratified K-fold Cross Validation method.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Ppojp2h9mLGL"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableParallel\n",
        "parallel_chain= RunnableParallel(\n",
        "    summary= prompt3 | model1 | parser,\n",
        "    quiz= prompt4 | model1 | parser,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "vdp4MVY18Lqs"
      },
      "outputs": [],
      "source": [
        "seq_chain= prompt5 | model2 | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "TBz8JGS48SfK"
      },
      "outputs": [],
      "source": [
        "final_chain= parallel_chain | seq_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "0sgRQZQJ8c3_",
        "outputId": "34ac4204-6e9e-4149-a5a7-f67b5bdbd698"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The article emphasizes the significance of balancing imbalanced datasets in classification modeling, using a combination of oversampling and undersampling techniques. It introduces the SMOTE-ENN method, which merges SMOTE for creating synthetic examples for the minority class and ENN for eliminating observations with different classes from their K-nearest neighbors. The concepts of K-Nearest Neighbor (KNN) and Edited Nearest Neighbor (ENN) are thoroughly explained. The KNN concept assumes that the nearest neighbor of each data point, based on its distance, belongs to a similar class. On the other hand, ENN works by identifying the K-nearest neighbor of each observation and deleting them if they belong to different classes. The SMOTE-ENN method is detailed step by step, including its implementation in Python using the imbalanced-learn library. The AdaBoost Classifier is utilized as the model, and the Repeated Stratified K-fold Cross Validation method is used for evaluation.\\n\\nQuiz:\\n1. What is the primary reason for combining SMOTE with Edited Nearest Neighbor (ENN) in balancing datasets for classification modeling?\\na) To enhance the model performance\\nb) To decrease the model performance\\nc) To make the dataset more imbalanced\\nd) To make the dataset more biased\\n\\n2. What is the K-Nearest Neighbor (KNN) concept in the context of balancing datasets?\\na) It assumes that the nearest neighbor of each data point, based on its distance, belongs to a similar class\\nb) It assumes that the farthest neighbor of each data point, based on its distance, belongs to a similar class\\nc) It assumes that the nearest neighbor of each data point, based on its distance, belongs to a different class\\nd) It assumes that the farthest neighbor of each data point, based on its distance, belongs to a different class\\n\\n3. What is the Edited Nearest Neighbor (ENN) concept in the context of balancing datasets?\\na) It works by identifying the K-nearest neighbor of each observation and deleting them if they belong to different classes\\nb) It works by identifying the K-nearest neighbor of each observation and keeping them if they belong to different classes\\nc) It works by identifying the 1-nearest neighbor of each observation and deleting them if they belong to different classes\\nd) It works by identifying the 1-nearest neighbor of each observation and keeping them if they belong to different classes\\n\\n4. How does the SMOTE-ENN method combine the SMOTE and ENN techniques to balance datasets?\\na) By creating synthetic examples for the minority class using SMOTE and eliminating observations with different classes using ENN\\nb) By creating synthetic examples for the majority class using SMOTE and eliminating observations with different classes using ENN\\nc) By creating synthetic examples for both classes using SMOTE and eliminating observations with different classes using ENN\\nd) By creating synthetic examples for the minority class using SMOTE and retaining all observations using ENN.'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_chain.invoke({\"para\":sample_text})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rO9rGfmd8VTq",
        "outputId": "008ba881-a288-491a-83d7-73de2a7c435f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          +-----------------------------+            \n",
            "          | Parallel<summary,quiz>Input |            \n",
            "          +-----------------------------+            \n",
            "                 **               **                 \n",
            "              ***                   ***              \n",
            "            **                         **            \n",
            "+----------------+                +----------------+ \n",
            "| PromptTemplate |                | PromptTemplate | \n",
            "+----------------+                +----------------+ \n",
            "          *                               *          \n",
            "          *                               *          \n",
            "          *                               *          \n",
            "  +------------+                    +------------+   \n",
            "  | ChatOpenAI |                    | ChatOpenAI |   \n",
            "  +------------+                    +------------+   \n",
            "          *                               *          \n",
            "          *                               *          \n",
            "          *                               *          \n",
            "+-----------------+              +-----------------+ \n",
            "| StrOutputParser |              | StrOutputParser | \n",
            "+-----------------+              +-----------------+ \n",
            "                 **               **                 \n",
            "                   ***         ***                   \n",
            "                      **     **                      \n",
            "          +------------------------------+           \n",
            "          | Parallel<summary,quiz>Output |           \n",
            "          +------------------------------+           \n",
            "                          *                          \n",
            "                          *                          \n",
            "                          *                          \n",
            "                 +----------------+                  \n",
            "                 | PromptTemplate |                  \n",
            "                 +----------------+                  \n",
            "                          *                          \n",
            "                          *                          \n",
            "                          *                          \n",
            "                   +------------+                    \n",
            "                   | ChatOpenAI |                    \n",
            "                   +------------+                    \n",
            "                          *                          \n",
            "                          *                          \n",
            "                          *                          \n",
            "                +-----------------+                  \n",
            "                | StrOutputParser |                  \n",
            "                +-----------------+                  \n",
            "                          *                          \n",
            "                          *                          \n",
            "                          *                          \n",
            "              +-----------------------+              \n",
            "              | StrOutputParserOutput |              \n",
            "              +-----------------------+              \n"
          ]
        }
      ],
      "source": [
        "final_chain.get_graph().print_ascii()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6HzVagDBtrg"
      },
      "source": [
        "## Conditional Chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6NfMteWQDadP"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "parser_json= JsonOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "4ANQrnxS8X0t"
      },
      "outputs": [],
      "source": [
        "prompt6= PromptTemplate(\n",
        "    input_variables=[\"feedback\"],\n",
        "    template=\"\"\"Analyze the sentiment of the following customer feedback {feedback}\\n.\n",
        "    Classify it as Positive, Negative, or Neutral. Then, provide a brief explanation highlighting the key phrases or words that led to your classification.\n",
        "    Also, summaries it in short.\n",
        "    give me in output in sentiment, explaination and summary key. {format_instruction}\"\"\",\n",
        "    partial_variables={\"format_instruction\": parser_json.get_format_instructions()},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "ww4puNrJDJb_"
      },
      "outputs": [],
      "source": [
        "chain_sentiment= prompt6 | model1 | parser_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLGnLR31EiAD",
        "outputId": "715ba4d9-91e2-443e-bb7e-5fe5b7982fe9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sentiment': 'Neutral',\n",
              " 'explanation': 'The customer feedback mentions that the mobile is a good product but suggests that it would be worth buying if it had more RAM. This indicates a neutral sentiment as the customer is overall satisfied with the product but sees room for improvement.',\n",
              " 'summary': 'Satisfied with the product but suggests improvement with more RAM.'}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain_sentiment.invoke({\"feedback\":\"This mobile should worth buying if more RAM is provided into it, but overall it is good product.\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "lowa7LqdGpFF"
      },
      "outputs": [],
      "source": [
        "prompt7 = PromptTemplate(\n",
        "    input_variables=[\"sentiment\", \"summary\"],\n",
        "    template=\"\"\"Write an gentle, simple, appropriate and always thankful for the feeback kind response for the positive and neutral.\\n {sentiment} and if possible try to add few points from summary.\\n {summary} .\"\"\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "AqxOmGxyHzMa"
      },
      "outputs": [],
      "source": [
        "prompt8= PromptTemplate(\n",
        "    input_variables=[\"sentiment\", \"summary\"],\n",
        "    template=\"\"\"Write an thankful for the feeback and try to make it like that customer is very valuable and we will definately improve on the points mentioned in the negative sentiment{sentiment}\\n. if possible to add few points from following summary {summary}.\"\"\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "8EaRBny6Errc"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableBranch, RunnableLambda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "MC43tYAFGi90"
      },
      "outputs": [],
      "source": [
        "branch_chain= RunnableBranch(\n",
        "    (lambda x: x[\"sentiment\"] == \"Positive\", prompt7 | model1 | parser),\n",
        "    (lambda x: x[\"sentiment\"] == \"Negative\", prompt8 | model1 | parser),\n",
        "    (lambda x: x[\"sentiment\"] == \"Neutral\", prompt7 | model1 | parser),\n",
        "    # Add a default branch to handle other cases\n",
        "    RunnableLambda(lambda x: \"Unable to classify sentiment.\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "8rJ1VIQcKgJP"
      },
      "outputs": [],
      "source": [
        "chain_final= chain_sentiment | branch_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "VrMJ1bsnK9xW",
        "outputId": "bcf784a6-7064-4bb0-f16f-253464cd30d8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Thank you so much for your kind words and positive feedback! We are thrilled to hear that you think our product is the best you have ever seen. Your satisfaction is our top priority, and we are grateful for your support. We will continue to strive for excellence and provide you with the best products and service possible. Thank you again for taking the time to share your experience with us!'"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain_final.invoke({\"feedback\":\"This is good product i ever seen.\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xsmmlvq2LARm",
        "outputId": "d3d95750-4b26-4641-96dc-af9a90d5fa9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  +-------------+    \n",
            "  | PromptInput |    \n",
            "  +-------------+    \n",
            "          *          \n",
            "          *          \n",
            "          *          \n",
            " +----------------+  \n",
            " | PromptTemplate |  \n",
            " +----------------+  \n",
            "          *          \n",
            "          *          \n",
            "          *          \n",
            "   +------------+    \n",
            "   | ChatOpenAI |    \n",
            "   +------------+    \n",
            "          *          \n",
            "          *          \n",
            "          *          \n",
            "+------------------+ \n",
            "| JsonOutputParser | \n",
            "+------------------+ \n",
            "          *          \n",
            "          *          \n",
            "          *          \n",
            "     +--------+      \n",
            "     | Branch |      \n",
            "     +--------+      \n",
            "          *          \n",
            "          *          \n",
            "          *          \n",
            "  +--------------+   \n",
            "  | BranchOutput |   \n",
            "  +--------------+   \n"
          ]
        }
      ],
      "source": [
        "chain_final.get_graph().print_ascii()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUwE9czeLcUD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
