# Forward Propagation is the process of passing input data through the layers of a neural network to get the final output.

## It happens layer by layer, using:
## Weights
## Biases
## Activation Functions (like sigmoid, ReLU)

## For input x, weights w, bias b:
## ğ‘§=ğ‘¤â‹…ğ‘¥+ğ‘(linearÂ step)
## ğ‘=ğœ(ğ‘§)(activationÂ step,Â e.g.,Â sigmoid)
